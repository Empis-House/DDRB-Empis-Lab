# DDRB-Empis-Lab

# Temp: Code must be runned from DDRB-Empis-Lab/Scripte and axecuting Map_Grammars_Elite.py
 
 
Principal Objective:
Create a model which accelerates and diversifies the learning process of classic mario bros game-play ML models via Procedural Content Generation ML and a variant of Dynamic Difficulty Adjustment where we propose that it is necessarily considered a reward-difficulty balancing stead a direct Difficulty Adjustment.

Sub Objectives:

      1. PCGML model which considered a latent representation of a Level and the User/Agent Jump performance description.
    
      2. Map Elite Grammar representations of a generative bases of preselected feasible sub-levels which represents a great variety on an fixed expected jump performance space.
    
      3. A RL Agent to Balancing Reward component, seting all reward* across the level to induce the User/Agent to the expected jump performance.
    
      4. An Environment Manager which controls hyperparameters of previous components to Optimize long term User/Agent results with creciente Objective performance.
    
* Also we expect to test it in a real game, with a version of the Dynamic Difficulty Reward Balancing trained with multiple Artificial Agents. 

Notes: Concidere a hestocastic definition of Reward where we can reprecented for example: an enemy wich is potencial negative reward if it kills you, but also is a potencial positive reward if you do it before.

**DOCUMENT IN PROGRESS**
